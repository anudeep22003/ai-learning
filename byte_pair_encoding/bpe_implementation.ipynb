{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5735ce81-fc78-4ded-a842-1b0be13e44c1",
   "metadata": {},
   "source": [
    "# Byte Pair Encoding \n",
    "## Implementing the algorithm to better understand the moving parts\n",
    "\n",
    "BPE does the follow steps recursively until the required vocab size is reached\n",
    "- pre-tokenize to get individual words\n",
    "- pad both sides of the word with `\\w` \n",
    "- compute frequencies of pairs, the pair with the highest frequency gets merged into a single token and gets added to the dictionary \n",
    "\n",
    "### Data structures\n",
    "- vocab: the set of unique tokens, needs to be updated after every new merge rule\n",
    "- corpus: the set of tokenized words with their frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212349b5-ef9e-4e8d-9d16-1e8eb6bb855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint as pp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258b3d00-60bb-4d8e-a152-97fd3dc04552",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"\"\"\n",
    "I am the a hero. \n",
    "I am looking for a villain because I am bored. \n",
    "What is the point of being a hero if there is no villain. \n",
    "Then all I am is a person, and that is not fun enough. \n",
    "So, villain, where are you?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9a64d-81ed-4318-ae22-fb87f2cc3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"\"\"\n",
    "Entropy is a scientific concept, as well as a measurable physical property, that is most commonly associated with a state of disorder, randomness, or uncertainty. The term and the concept are used in diverse fields, from classical thermodynamics, where it was first recognized, to the microscopic description of nature in statistical physics, and to the principles of information theory. It has found far-ranging applications in chemistry and physics, in biological systems and their relation to life, in cosmology, economics, sociology, weather science, climate change, and information systems including the transmission of information in telecommunication.\n",
    "\n",
    "The thermodynamic concept was referred to by Scottish scientist and engineer William Rankine in 1850 with the names thermodynamic function and heat-potential. In 1865, German physicist Rudolf Clausius, one of the leading founders of the field of thermodynamics, defined it as the quotient of an infinitesimal amount of heat to the instantaneous temperature. He initially described it as transformation-content, in German Verwandlungsinhalt, and later coined the term entropy from a Greek word for transformation. Referring to microscopic constitution and structure, in 1862, Clausius interpreted the concept as meaning disgregation.\n",
    "\n",
    "A consequence of entropy is that certain processes are irreversible or impossible, aside from the requirement of not violating the conservation of energy, the latter being expressed in the first law of thermodynamics. Entropy is central to the second law of thermodynamics, which states that the entropy of isolated systems left to spontaneous evolution cannot decrease with time, as they always arrive at a state of thermodynamic equilibrium, where the entropy is highest.\n",
    "\n",
    "Austrian physicist Ludwig Boltzmann explained entropy as the measure of the number of possible microscopic arrangements or states of individual atoms and molecules of a system that comply with the macroscopic condition of the system. He thereby introduced the concept of statistical disorder and probability distributions into a new field of thermodynamics, called statistical mechanics, and found the link between the microscopic interactions, which fluctuate about an average configuration, to the macroscopically observable behavior, in form of a simple logarithmic law, with a proportionality constant, the Boltzmann constant, that has become one of the defining universal constants for the modern International System of Units (SI).\n",
    "\n",
    "In 1948, Bell Labs scientist Claude Shannon developed similar statistical concepts of measuring microscopic uncertainty and multiplicity to the problem of random losses of information in telecommunication signals. Upon John von Neumann's suggestion, Shannon named this entity of missing information in analogous manner to its use in statistical mechanics as entropy, and gave birth to the field of information theory. This description has been identified as a universal definition of the concept of entropy. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c191402-b233-4cac-ab7c-563f4714d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_word_with_start_token(word:list):\n",
    "    if word is None:\n",
    "        return None\n",
    "    else:\n",
    "        return word + '#'\n",
    "    \n",
    "# removed punctuations\n",
    "def remove_punctuation(word:list, punct:list = punct):\n",
    "    if len(word)==0:\n",
    "        return None\n",
    "    \n",
    "    if word[0] in punct:\n",
    "        word = word.replace(word[0],'')\n",
    "    if word[-1] in punct:\n",
    "        word = word.replace(word[-1],'')\n",
    "        \n",
    "    word = pad_word_with_start_token(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "410b3422-af20-4f59-95fe-1aa837c3e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 'ab']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l.append(\"a\"+\"b\")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f9a8885b-6744-452c-997c-74f91b1d88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'\",\n",
      " '(',\n",
      " ')',\n",
      " '-',\n",
      " '0',\n",
      " '1',\n",
      " '2',\n",
      " '4',\n",
      " '5',\n",
      " '6',\n",
      " '8',\n",
      " '9',\n",
      " 'a',\n",
      " 'a#',\n",
      " 'al',\n",
      " 'al#',\n",
      " 'an',\n",
      " 'and#',\n",
      " 'as#',\n",
      " 'at',\n",
      " 'ation#',\n",
      " 'b',\n",
      " 'c',\n",
      " 'co',\n",
      " 'con',\n",
      " 'd',\n",
      " 'd#',\n",
      " 'e',\n",
      " 'e#',\n",
      " 'ed#',\n",
      " 'en',\n",
      " 'ent',\n",
      " 'entrop',\n",
      " 'entropy#',\n",
      " 'er',\n",
      " 'f',\n",
      " 'f#',\n",
      " 'fi',\n",
      " 'for',\n",
      " 'g',\n",
      " 'g#',\n",
      " 'h',\n",
      " 'i',\n",
      " 'ic',\n",
      " 'in',\n",
      " 'in#',\n",
      " 'j',\n",
      " 'k',\n",
      " 'l',\n",
      " 'la',\n",
      " 'm',\n",
      " 'm#',\n",
      " 'mic',\n",
      " 'mo',\n",
      " 'mod',\n",
      " 'n',\n",
      " 'na',\n",
      " 'o',\n",
      " 'of#',\n",
      " 'on',\n",
      " 'or',\n",
      " 'p',\n",
      " 'q',\n",
      " 'r',\n",
      " 're',\n",
      " 'ro',\n",
      " 'rop',\n",
      " 's',\n",
      " 's#',\n",
      " 'si',\n",
      " 'st',\n",
      " 'st#',\n",
      " 't',\n",
      " 't#',\n",
      " 'th',\n",
      " 'the#',\n",
      " 'ther',\n",
      " 'ti',\n",
      " 'tion',\n",
      " 'tion#',\n",
      " 'to',\n",
      " 'to#',\n",
      " 'u',\n",
      " 'un',\n",
      " 'v',\n",
      " 'w',\n",
      " 'x',\n",
      " 'y',\n",
      " 'y#',\n",
      " 'z'}\n"
     ]
    }
   ],
   "source": [
    "punct = set(\".?,! \\n\")\n",
    "\n",
    "class BytePair:\n",
    "    def __init__(\n",
    "        self, \n",
    "        text: list, \n",
    "        punct:list, \n",
    "        vocab_size:int = 60,\n",
    "        verbose:bool = False,\n",
    "        debug = False\n",
    "        ):\n",
    "        self.verbose = verbose\n",
    "        self.debug = debug\n",
    "        self.vocab_size = vocab_size\n",
    "        self.text = text\n",
    "        self.merges = {}\n",
    "        self.build_byte_pairs()\n",
    "        \n",
    "    def pp_values(self):\n",
    "        rep = 10\n",
    "        print(\"\\n\" ,\"-\"*rep, \" word_freq \", \"-\"*rep, \"\\n\")\n",
    "        pp(self.word_freq)\n",
    "        print(\"\\n\" ,\"-\"*rep, \" base-tokens \", \"-\"*rep, \"\\n\")\n",
    "        pp(self.vocab)\n",
    "        print(\"\\n\" ,\"-\"*rep, \" char-splits \", \"-\"*rep, \"\\n\")\n",
    "        pp(self.char_splits)\n",
    "        print(\"\\n\" ,\"-\"*rep, \" bytepair-freq-table \", \"-\"*rep, \"\\n\")\n",
    "        pp(self.bytepair_table)\n",
    "        print(\"\\n\" ,\"-\"*rep, \" bytepair-freq-sorted-table \", \"-\"*rep, \"\\n\")\n",
    "        pp(self.find_most_freq_pair())\n",
    "    \n",
    "    def build_byte_pairs(self,):\n",
    "        self.word_freq = self.build_corpus()\n",
    "        self.vocab = self.extract_vocab()\n",
    "        self.char_splits = self.extract_character_splits()\n",
    "        \n",
    "        while len(self.vocab)<self.vocab_size:\n",
    "            if self.verbose:\n",
    "                print(f\"---- vocab size: {len(self.vocab)}\")\n",
    "            # compute pair frequencies to find most common pair to merge\n",
    "            new_merge_pair = self.find_most_freq_pair(\n",
    "               pair_freq = self.compute_pair_freq()\n",
    "            )\n",
    "            self.integrate_merge_pair(new_merge_pair)\n",
    "    \n",
    "    def integrate_merge_pair(self, merge_pair:tuple):\n",
    "        joined_pair = \"\".join(merge_pair)\n",
    "        self.merges[merge_pair] = joined_pair\n",
    "        self.vocab.add(joined_pair)\n",
    "        self.merge_pair_into_splits(merge_pair[0], merge_pair[1])\n",
    "    \n",
    "    def merge_pair_into_splits(self, c1:str, c2:str,):\n",
    "        if self.verbose:\n",
    "            print(\"----\", f\"new merge candidate: {(c1,c2)}\", \"----\")\n",
    "        for word, freq in self.word_freq.items():\n",
    "            split = self.char_splits[word]\n",
    "            new_split = []                      # the split is reconstructed and replaced. This variable is used to store, cleared at the start of new word\n",
    "            merge_candidate = []                # intermediate list, to keep track of potential merge candidates while looping through the word\n",
    "            merge_performed = False             # set to true if merge was performed on the word, helps with verbose output\n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            if split is None:\n",
    "                continue\n",
    "                \n",
    "            for c in split:\n",
    "                if c == c1:\n",
    "                    merge_candidate.append(c1)\n",
    "                elif c == c2:\n",
    "                    if len(merge_candidate) == 1:\n",
    "                        new_split.append(c1+c2)\n",
    "                        merge_performed = True\n",
    "                        merge_candidate = []\n",
    "                    else:\n",
    "                        new_split.append(c)\n",
    "                        continue\n",
    "\n",
    "                else:\n",
    "                    if len(merge_candidate) == 1:\n",
    "                        new_split.extend(merge_candidate)\n",
    "                    merge_candidate = []\n",
    "                    new_split.append(c)\n",
    "                \n",
    "                    \n",
    "            if self.verbose and merge_performed:\n",
    "                if self.debug:\n",
    "                    print(\"freq: --> \", freq, \"new split: --> \", word, split)\n",
    "                else:\n",
    "                    print(\"new split: --> \", word, split)\n",
    "            self.char_splits[word] = new_split\n",
    "            \n",
    "    def old_merge_pair_into_splits(self, c1:str, c2:str,):\n",
    "        \"\"\"\n",
    "        Originally wrote this but this method failed when the same merge pair occured twice in the same word. \n",
    "        Listindex out of bounds error was thrown. \n",
    "        To solve this, rewrote as the above function. \n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"----\", f\"new merge candidate: {(c1,c2)}\", \"----\")\n",
    "        for word in self.word_freq.keys():\n",
    "            split = self.char_splits[word]\n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            if split is None:\n",
    "                continue\n",
    "            for i in range(len(split)-1):\n",
    "                try:\n",
    "                    if split[i]==c1 and split[i+1]==c2:\n",
    "                        split = split[:i] + [c1 + c2] + split[i+2:]\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"*\"*10, \"failed at\", word, split, f\"merge-pair: {(c1,c2)}\", f\"index: {i}\", \"*\"*10)\n",
    "                    \n",
    "                    if self.verbose:\n",
    "                        print(\"freq: --> \", freq, \"new split: --> \", word, split)\n",
    "            self.char_splits[word] = split\n",
    "        \n",
    "        \n",
    "    def build_corpus(self,) -> dict:\n",
    "        tokens = [remove_punctuation(token) for token in self.text.lower().split()]\n",
    "        return Counter([t for t in tokens])\n",
    "\n",
    "    def extract_vocab(self,) -> set:\n",
    "        return set(self.text.lower()) - punct\n",
    "\n",
    "    def extract_character_splits(self) -> dict:\n",
    "        return {word:[c for c in word] for word in self.word_freq.keys()}\n",
    "    \n",
    "    def compute_pair_freq(self) -> dict:\n",
    "        pair_freqs = defaultdict(int)\n",
    "        for word,freq in self.word_freq.items(): \n",
    "            split = self.char_splits[word]\n",
    "            \n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            \n",
    "            for pair in zip(split,split[1:]):\n",
    "                pair_freqs[pair] += freq\n",
    "                \n",
    "        return pair_freqs\n",
    "    \n",
    "    def find_most_freq_pair(self, pair_freq: dict[tuple,int]) -> tuple:\n",
    "        \n",
    "        sorted_pairs = sorted(\n",
    "            pair_freq.items(), \n",
    "            key= lambda x: x[1], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        if self.verbose and self.debug:\n",
    "            print(sorted_pairs[0], \"max: -> \", max(sorted_pairs, key= lambda x: x[1]))\n",
    "        \n",
    "        return sorted_pairs[0][0]\n",
    "            \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_bytepair_pair_freq(tokens:list, counter: Counter = None) -> dict:\n",
    "        if counter is None:\n",
    "            counter = Counter()\n",
    "        for t in tokens:\n",
    "            for char1,char2 in zip(t,t[1:]):\n",
    "                counter.update([\"\".join(\n",
    "                    (char1,char2)\n",
    "                )])\n",
    "        return counter\n",
    "    \n",
    "\n",
    "b = BytePair(lang, punct, vocab_size=90, verbose=False, debug=False)\n",
    "pp(b.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "83f8e720-b06a-4bce-a381-8a6e845ddedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(b.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03fe0a92-12aa-4feb-b522-47cfc9c21d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = list(\".?,!\")\n",
    "tokens = [remove_punctuation(w) for w in lang.lower().split()]\n",
    "corpus = Counter(tokens)\n",
    "tokenized_corpus = Counter()\n",
    "\n",
    "    \n",
    "for word in corpus.keys():\n",
    "    tokenized_corpus.update(word)\n",
    "\n",
    "corpus, tokenized_corpus\n",
    "\n",
    "iter_frequencies = Counter()\n",
    "\n",
    "for w in corpus:\n",
    "    for merged_token in zip(w,w[1:]):\n",
    "        merged_token = \"\".join(merged_token)\n",
    "        iter_frequencies.update([merged_token])\n",
    "        \n",
    "for byte_pair in iter_frequencies.most_common(1):\n",
    "    # add the pair to the tokenized_corpus \n",
    "    # remove the counts from the framgments of the byte pair, remove entry if count goes to 0\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfc3a7-a125-4c06-895b-9e9f21650396",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq = {k,v for k,v in sorted(iter_frequencies.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4029f-34dc-47d5-983a-de9a5163bed9",
   "metadata": {},
   "source": [
    "(sentence: \"anudeep went to the park\")\n",
    "corpus: {word: frequency}\n",
    "- base dictionary, no computations done on this \n",
    "- {\"anudeep\":1, \"went\":1, \"to\":1, \"the\":1, \"park\":1}\n",
    "\n",
    "tokenized_corpus: {word: byte_pair_tokenized_word}\n",
    "- starts off as simple tokenization, over time the byte pair tokenization is updated here\n",
    "\n",
    "base_tokens: set{characters_that_make_up_tokens}\n",
    "- the set of base characters that make up all the tokens\n",
    "- no computations done on this \n",
    "byte_pair_freq_table: {byte_pairs: freq}\n",
    "- byte pairs and their frequency\n",
    "- this table will be used to calculate the next merge candidates \n",
    "\n",
    "```\n",
    "# Algorithm:\n",
    "\n",
    "1) sort the byte pairs by frequency\n",
    "2) use the last character, of the byte pair to \n",
    "\n",
    "for byte_pair in sorted(byte_pair_freq_table):\n",
    "    if byte_pair[-1] == '#':\n",
    "        continue\n",
    "    else:\n",
    "        for bp in byte_pair_freq_table:\n",
    "            if bp[0] == byte_pair[-1]:\n",
    "                \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "iter_freq: {merged_token: freq}\n",
    "\n",
    "Algorithm:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6093b-0a7e-4a8a-bf95-d39589c01e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(ai-playground)",
   "language": "python",
   "name": "ai-playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
